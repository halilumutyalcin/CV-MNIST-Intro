{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Numpy, MNIST, Keras and Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# NumPy - mathematical functions on multi-dimensional arrays and matrices\n",
    "import numpy as np\n",
    "# MNIST - digital database of handwritten digits\n",
    "import mnist\n",
    "\n",
    "# Matplotlib - plotting library to create graphs and charts\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# Keras - Python open-source neural-network library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing train and test images from MNIST. Keeping original images to display some digits initially and during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 60000 images and the size of image is 28 x 28 pixels, represented as 28 by 28 matrix of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we normalise our traning data let's grab some images for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_display = train_images[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalise and flatten our training images data. This is a better format too use for our Neural Network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training array has a shape (60000, 784)\n",
      "Each element (image) has a shape (784,)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "\n",
    "# Flatten the images - changing the dimension of the array from 28 x 28 to 1 x 784.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "\n",
    "print('Our training array has a shape ' + str(train_images.shape))\n",
    "print('Each element (image) has a shape ' + str(train_images[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's print some digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing some digits using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images - it takes a lot of memory so skip if you can\n",
    "f = plt.figure(figsize=(10,5))\n",
    "columns = 5\n",
    "images = train_images_display[:20]\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "    # imshow displays array-like images\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.show()\n",
    "f.clear()\n",
    "plt.close(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Artificial Neural Network model with Keras. Our Neural Network has 1 input layer, 1 hidden layer, and 1 output layer.\n",
    "\n",
    "We are creating our model which groups layers into an object. The sequential model is suitable for most problems. It does not allow you to create models that share layers or have multiple inputs or outputs.\n",
    "\n",
    "We are using Dense layers in our NN which are regular densely-connected NN layers. Densely-connected means that each neuron in a layer receives an input from all the neurons in the previous layer.\n",
    "\n",
    "The input_shape specifies the dimension of the input data. In our example it is an image 28 by 28 pixels that we have flattened to (784,).\n",
    "\n",
    "The output layer has to have the same number of nodes that we expect results. In our example we are expecting a result from 0 to 9 which means we need 10 nodes in the output.\n",
    "\n",
    "We are using softmax activation function for the output that converts a real vector to a vector of categorical probabilities. The elements of the output vector are in range (0, 1).\n",
    "\n",
    "How are we going to get a result from 0 to 9?. We will convert our labels during training to an array using Keras to_categorical function and our output from Neural Network will be in the same format.\n",
    "\n",
    "This means that 1 for example will be represented as [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], 2 will be represented as [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.] and our results for each digits will look like this [1.9625609e-06 6.5977215e-09 1.7479050e-04 2.1603969e-03 1.0921193e-08 1.1998044e-05 9.2225836e-12 9.9754709e-01 2.6972772e-05 7.6780409e-05] which will give us probabilities which number is the most probable result.\n",
    "\n",
    "Other layer in our Neural Network use ReLU activation function. ReLU is the most commonly used activation function in neural networks. You can experiment and learn more about diffeernt activation functions on Keras documentation (https://keras.io/api/layers/activations/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is created we need to compile it. We need to specify two required arguments: optimizer and loss function.\n",
    "\n",
    "Optimizer is an optimization algorithm that is used to optimize the training process and adjust the weights on the nodes that lead towards a solution. We will use optimizer that implements the Adam algorithm. Adam is a stochastic gradient descent method (https://keras.io/api/optimizers/adam/) and it is probably the most popular optimizer and it usually performs well.\n",
    "\n",
    "Loss function computes the quantity that a model should aim to minimize during training (https://keras.io/api/losses/). We will be using categorical_crossentropy functioon.\n",
    "\n",
    "We are also specifying metrics that are displayed during calling fit() function and trining our model. In our project we will \"accuracy\" to see how the accuracy changes after each Epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model (Option 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be now training out model using model.fit() function.\n",
    "\n",
    "We provide train images to the function and the labels. Labels (dependant variables) are converted from a vector (integer) to binary class matrix. Epoch is one pass over the entire dataset and batch_size is the number of images train during one pass though a Neural Network. You can experiment with the number of epochs and batch size to opimise training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.3635 - accuracy: 0.8899\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1863 - accuracy: 0.9430\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1436 - accuracy: 0.9551\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1174 - accuracy: 0.9629\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.1008 - accuracy: 0.9693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f92f3b4b810>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_images, # training data\n",
    "  to_categorical(train_labels), # training targets\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model (Option 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our model is trained we can save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model (Option 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving a model enables us to just load the model without the need of it being train again.\n",
    "\n",
    "In our project we can train the model quickly but training of a complex Neural Network models can take hours or days and saving a model is a useful thing to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model's saved weights.\n",
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare some testing data so we can test the performance of our model.\n",
    "\n",
    "We take test images and labels from the mnist library, normalize the test images values for better model performance and flatten the images matrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "# Normalize the images.\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Flatten the images.\n",
    "test_images = test_images.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are giving our models to the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 39us/step\n",
      "loss: 0.10312977911322378\n",
      "accuracy: 0.9657999873161316\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")\n",
    "\n",
    "print(model.metrics_names[0] + ': ' + str(result[0]))\n",
    "print(model.metrics_names[1] + ': ' + str(result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the results are not satisfactory we can go back and reconfigure our Network and increase the number of layers or nodes.\n",
    "\n",
    "We cal also go back to the training and model.fit() function and change the number of epochs or batch_size and see if we get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's make some predictions using first five elements of the testinng data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4]\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
